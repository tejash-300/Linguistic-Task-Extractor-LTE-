{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOHjOXHV01iP84/MeLe+GWi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# First, install all required packages\n","# First, install all required packages\n","!pip install -q nltk spacy gensim scikit-learn\n","\n","import nltk\n","import spacy\n","import re\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import warnings\n","warnings.filterwarnings('ignore')\n","# Download the 'averaged_perceptron_tagger_eng' data package\n","nltk.download('averaged_perceptron_tagger_eng') # This line is added to download the required data\n","\n","\n","# Download all required NLTK data\n","print(\"Downloading NLTK resources...\")\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","# Download the 'punkt_tab' data package\n","nltk.download('punkt_tab') # This line is added to download the required data\n","print(\"NLTK resources downloaded successfully!\")\n","\n","# Download spaCy model\n","print(\"Downloading spaCy model...\")\n","!python -m spacy download en_core_web_sm\n","print(\"spaCy model downloaded successfully!\")\n","# ... (rest of your code remains the same) ...\n","\n","class TaskExtractor:\n","    def __init__(self):\n","        self.nlp = spacy.load('en_core_web_sm')\n","        self.lemmatizer = WordNetLemmatizer()\n","        self.stop_words = set(stopwords.words('english'))\n","\n","        # Action verbs that typically indicate tasks\n","        self.action_verbs = {\n","            'complete', 'finish', 'submit', 'prepare', 'review', 'create',\n","            'update', 'send', 'schedule', 'organize', 'buy', 'clean', 'write',\n","            'implement', 'develop', 'design', 'analyze', 'investigate'\n","        }\n","\n","        # Modal verbs and obligation words\n","        self.modal_words = {\n","            'must', 'should', 'need', 'have to', 'has to', 'needs to',\n","            'required to', 'supposed to'\n","        }\n","\n","    def preprocess_text(self, text):\n","        # Basic text cleaning\n","        text = text.lower()\n","        text = re.sub(r'[^\\w\\s.]', ' ', text)\n","        return text\n","\n","    def extract_sentences(self, text):\n","        # Using spaCy for sentence tokenization instead of NLTK\n","        doc = self.nlp(text)\n","        return [sent.text.strip() for sent in doc.sents]\n","\n","    def is_task_sentence(self, sentence):\n","        doc = self.nlp(sentence.lower())\n","\n","        # Check for modal verbs and obligation words\n","        has_modal = any(modal in sentence.lower() for modal in self.modal_words)\n","\n","        # Check for action verbs\n","        tokens = word_tokenize(sentence.lower())\n","        pos_tags = pos_tag(tokens)\n","        verbs = [word for word, tag in pos_tags if tag.startswith('VB')]\n","        has_action_verb = any(self.lemmatizer.lemmatize(v) in self.action_verbs for v in verbs)\n","\n","        # Check for future tense or imperative mood\n","        has_future = any(word in sentence.lower() for word in ['will', 'going to'])\n","\n","        # Check for imperative mood (sentence starting with verb)\n","        starts_with_verb = len(pos_tags) > 0 and pos_tags[0][1].startswith('VB')\n","\n","        return has_modal or has_action_verb or has_future or starts_with_verb\n","\n","    def extract_entity(self, sentence):\n","        doc = self.nlp(sentence)\n","\n","        # Look for named entities\n","        people = [ent.text for ent in doc.ents if ent.label_ in ['PERSON', 'ORG']]\n","\n","        # Look for subject pronouns if no named entities found\n","        if not people:\n","            for token in doc:\n","                if token.dep_ == 'nsubj':\n","                    return token.text\n","\n","        return people[0] if people else None\n","\n","    def extract_deadline(self, sentence):\n","        doc = self.nlp(sentence)\n","\n","        # Time patterns\n","        time_patterns = [\n","            r'by\\s+(.*?)(?=\\.|$)',\n","            r'due\\s+(.*?)(?=\\.|$)',\n","            r'before\\s+(.*?)(?=\\.|$)',\n","            r'(?:today|tomorrow|tonight)',\n","            r'(?:\\d{1,2}(?::\\d{2})?\\s*(?:am|pm))',\n","            r'(?:\\d{1,2}/\\d{1,2}/\\d{2,4})',\n","            r'next\\s+(?:monday|tuesday|wednesday|thursday|friday|saturday|sunday)',\n","            r'(?:this|next)\\s+(?:week|month|year)'\n","        ]\n","\n","        for pattern in time_patterns:\n","            match = re.search(pattern, sentence.lower())\n","            if match:\n","                return match.group()\n","\n","        return None\n","\n","    def categorize_task(self, task):\n","        categories = {\n","            'PURCHASE': ['buy', 'purchase', 'order', 'shop'],\n","            'MAINTENANCE': ['clean', 'fix', 'repair', 'maintain'],\n","            'COMMUNICATION': ['send', 'email', 'call', 'contact', 'inform'],\n","            'DEVELOPMENT': ['develop', 'code', 'program', 'implement'],\n","            'PLANNING': ['schedule', 'plan', 'organize', 'arrange'],\n","            'REVIEW': ['review', 'check', 'analyze', 'evaluate'],\n","            'DOCUMENTATION': ['document', 'write', 'report', 'draft'],\n","            'MEETING': ['meet', 'discuss', 'conference', 'sync']\n","        }\n","\n","        task_lower = task.lower()\n","        for category, keywords in categories.items():\n","            if any(keyword in task_lower for keyword in keywords):\n","                return category\n","\n","        return 'GENERAL'\n","\n","    def extract_tasks(self, text):\n","        # Preprocess text\n","        cleaned_text = self.preprocess_text(text)\n","\n","        # Extract sentences using spaCy\n","        sentences = self.extract_sentences(cleaned_text)\n","\n","        tasks = []\n","        for sentence in sentences:\n","            if self.is_task_sentence(sentence):\n","                task_info = {\n","                    'task': sentence.strip(),\n","                    'assignee': self.extract_entity(sentence),\n","                    'deadline': self.extract_deadline(sentence),\n","                    'category': self.categorize_task(sentence)\n","                }\n","                tasks.append(task_info)\n","\n","        return tasks\n","\n","# Test the implementation\n","def main():\n","    # Create test text\n","    test_text = \"\"\"\n","    Rahul wakes up early every day. He goes to college in the morning and comes back at 3 pm.\n","    At present, Rahul is outside. He has to buy the snacks for all of us.\n","    Sarah must complete the project report by Friday.\n","    The team needs to review the code before deployment tomorrow.\n","    Please clean the meeting room by 5 pm today.\n","    John will send the presentation to the client next week.\n","    Schedule a meeting with the development team for Monday.\n","    \"\"\"\n","\n","    # Initialize the task extractor\n","    extractor = TaskExtractor()\n","\n","    # Extract tasks\n","    tasks = extractor.extract_tasks(test_text)\n","\n","    # Print results\n","    print(\"\\nExtracted Tasks:\")\n","    print(\"-\" * 50)\n","    for i, task in enumerate(tasks, 1):\n","        print(f\"\\nTask {i}:\")\n","        print(f\"Description: {task['task']}\")\n","        print(f\"Assignee: {task['assignee'] or 'Not specified'}\")\n","        print(f\"Deadline: {task['deadline'] or 'Not specified'}\")\n","        print(f\"Category: {task['category']}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xc-DfvRU7_yL","executionInfo":{"status":"ok","timestamp":1738739838935,"user_tz":-330,"elapsed":19798,"user":{"displayName":"Tejash Pandey","userId":"07192226250705781138"}},"outputId":"c386a3e6-961e-45e4-f2f6-34984dfaf1f2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Downloading NLTK resources...\n","NLTK resources downloaded successfully!\n","Downloading spaCy model...\n","Collecting en-core-web-sm==3.7.1\n","  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","spaCy model downloaded successfully!\n","\n","Extracted Tasks:\n","--------------------------------------------------\n","\n","Task 1:\n","Description: he has to buy the snacks for all of us.\n","Assignee: he\n","Deadline: Not specified\n","Category: PURCHASE\n","\n","Task 2:\n","Description: sarah must complete the project report by friday.\n","Assignee: sarah\n","Deadline: by friday\n","Category: DOCUMENTATION\n","\n","Task 3:\n","Description: the team needs to review the code before deployment tomorrow.\n","Assignee: team\n","Deadline: before deployment tomorrow\n","Category: DEVELOPMENT\n","\n","Task 4:\n","Description: please clean the meeting room by 5 pm today.\n","Assignee: Not specified\n","Deadline: by 5 pm today\n","Category: MAINTENANCE\n","\n","Task 5:\n","Description: john will send the presentation to the client next week.\n","Assignee: john\n","Deadline: next week\n","Category: COMMUNICATION\n"]}]}]}